{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be the main file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function with preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_preprocess_IMDB(filename, nrows=None):\n",
    "    \"\"\" load the IMDB data and preprocess it:\n",
    "            - remove html tags\n",
    "            - remove ponctuation\n",
    "            - convert to lower case\n",
    "            - remove stop words\n",
    "            - remove numbers\n",
    "            - remove extra spaces\n",
    "            - replave words with their root form (stem)\n",
    "            - replace words with their lemma\n",
    "        :param dataset: 'train' or 'test'\n",
    "        :param nrows: number of rows to read\n",
    "        :return: df\n",
    "    \"\"\"\n",
    "\n",
    "    # read the data\n",
    "    df = pd.read_csv(filename, nrows=nrows)\n",
    "\n",
    "    # keep a copy of the original review\n",
    "    df['original_review'] = df['review']\n",
    "\n",
    "    # remove the html tags\n",
    "    df['review'] = df['review'].str.replace('<br />', ' ')\n",
    "\n",
    "    # remove the punctuation and '_' characters\n",
    "    df['review'] = df['review'].str.replace('[^\\w\\s]', ' ', regex=True)\n",
    "    df['review'] = df['review'].str.replace('_', ' ', regex=False)\n",
    "\n",
    "    # convert to lower case\n",
    "    df['review'] = df['review'].str.lower()\n",
    "\n",
    "    # remove the stop words\n",
    "    from nltk.corpus import stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    df['review'] = df['review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "    # remove the numbers - test on https://regexr.com\n",
    "    df['review'] = df['review'].str.replace('\\d+', '', regex=True)\n",
    "\n",
    "    # remove the extra spaces - test on https://regexr.com\n",
    "    df['review'] = df['review'].str.replace(' +', ' ', regex=True)\n",
    "\n",
    "    # replace the words with their root form\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    df['review'] = df['review'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "\n",
    "    # replace the words with their lemma\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df['review'] = df['review'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_preprocess_IMDB('./data/imdb_data_train.zip')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the data grouped by sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by='sentiment').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate de BOW Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(lowercase=True, # it should already be in lower case...\n",
    "                                   stop_words='english', # stop words should already have been removed but ...\n",
    "                                   ngram_range = (1, 1))\n",
    "\n",
    "cv.fit(df['review'])\n",
    "count_vectors_train = cv.transform(df['review'])\n",
    "count_vectors_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a dataframe with BoW and add the sentiment column (for an easier visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_train = pd.DataFrame(count_vectors_train.toarray(), columns=cv.get_feature_names_out())\n",
    "bow_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a simple Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# this can take a while... +1h on M1\n",
    "tree = DecisionTreeClassifier(\n",
    "    max_depth=3, # was 20c\n",
    ")\n",
    "tree.fit(bow_train, df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the test data and pass it through the BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = load_and_preprocess_IMDB('./data/imdb_data_test.zip')\n",
    "count_vectors_test = cv.transform(df_test['review'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
